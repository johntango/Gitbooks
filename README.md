---
description: Taken from Dale on AI
---

# Transformers

{% embed url="https://daleonai.com/transformers-explained" %}
from Daleonai.com
{% endembed %}

![](.gitbook/assets/TransformerArchitecture.png)

* Positional Encodings
  * \[("The", 1), ("aliens", 2), ("say", 3), ("hello", 4)]
  * Put structure into the data
* Attention
  * _The agreement on the European Economic Area was signed in August 1992._
  * _L’accord sur la zone économique européenne a été signé en août 1992._



![](.gitbook/assets/Attention001.png)

* Self-Attention
  * “Server, can I have the check?”
  * “Looks like I just crashed the server.”

### History - A Hammer for all nails

**BERT**, short for “Bidirectional Encoder Representations from Transformers”, was introduced by researchers at Google around 2018

&#x20;It can do&#x20;

* text summarization
* question answering
* classification
* named entity resolution
* text similarity
* offensive message/profanity detection
* understanding user queries
* a whole lot more

[MEENA ](https://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html)  introduced by Google Research 2022, is a Transformer-based chatbot (“conversational agent”) that can have compelling conversations about almost any topic&#x20;

Transformers can generate a wide variety of novel entities, including

* Magenta Music [https://magenta.tensorflow.org/music-transformer](https://magenta.tensorflow.org/music-transformer)
* DALLE-2 generating images from text  [https://daleonai.com/dalle-5-mins](https://daleonai.com/dalle-5-mins)&#x20;

**HuggingFaces** - Getting Started with Code

## Getting Started with Code

Transformers” library maintained by the company [HuggingFace](https://huggingface.co/). The platform allow you to train and use most of today’s popular NLP models, like BERT, Roberta, T5, GPT-2, in a very developer-friendly way.

\
